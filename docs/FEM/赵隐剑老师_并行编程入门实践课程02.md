# 赵隐剑老师_并行编程入门实践课程 02

* 该笔记对应以下 b 站视频，主要讲 MPI 的使用
	*  [并行编程入门与实践4](https://www.bilibili.com/video/BV1PQU2YvE8J/?spm_id_from=333.788.recommend_more_video.4&vd_source=b7bbd99721bfe117cc47d14c9f45af86)

其它 MPI 教程:
	* [Paul Norvig's basic Guide](https://www.paulnorvig.com/guides/using-mpi-with-c.html) 
	* [MPI tutorial](https://mpitutorial.com/tutorials/) 本篇笔记主要参考的是这个

[TOC]


---

## MPI

MPI（Message Passing Interface），主要是处理进程之间消息通信。

通讯器（communicator）。通讯器定义了一组能够互相发消息的进程。在这组进程中，每个进程会被分配一个序号，称作**秩（rank）**。

通信的基础建立在不同进程间发送和接收操作。一个进程可以通过指定另一个进程的秩以及一个独一无二的消息标签（tag）来发送消息给另一个进程。接受者可以发送一个接收特定标签标记的消息的请求（或者也可以完全不管标签，接收任何消息），然后依次处理接收到的数据。类似这样的涉及一个发送者以及一个接受者的通信被称作点对点（point-to-point）通信。

当然在很多情况下，某个进程可能需要跟所有其他进程通信。比如主进程想发一个广播给所有的从进程。在这种情况下，手动去写一个个进程点对点的信息传递就显得很笨拙。而且事实上这样会导致网络利用率低下。MPI 有专门的接口来帮我们处理这类所有进程间的集体性（collective）通信。

编译:

```cpp
mpic++ main.cpp -o main
mpirun -np 4 ./main
```


* 例子

```cpp
#include <mpi.h>        // MPI header for parallel functions
#include <iostream>     // For std::cout, std::endl
#include <thread>       // For std::this_thread::sleep_for
#include <chrono>       // For std::chrono::seconds

int main(int argc, char* argv[]) {
    // Initialize the MPI execution environment
    MPI_Init(&argc, &argv);

    // Retrieve the rank (ID) of this process and the total number of processes
    int rank = 0;
    int size = 0;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    std::cout << "mpi_i, mpi_n: " << rank << ", " << size << std::endl;

    // Sleep for a short duration to mimic the original behavior
    // Using std::this_thread::sleep_for and std::chrono provides type safety and clarity
    std::this_thread::sleep_for(std::chrono::seconds(1));

    // Synchronize all processes at this barrier
    // No process moves past this point until all have reached it
    MPI_Barrier(MPI_COMM_WORLD);

    // Only the root process (rank 0) performs this action
    if (rank == 0) {
        std::cout << "Only 0 does this." << std::endl;
    }

    // Cleanly shut down the MPI execution environment
    MPI_Finalize();

    return 0; // Indicate successful execution
}
```


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE3ODExNzUsLTIwNzMzMDU2MSwtMzE0ND
AzNjIyLC02NDg3NzM5MDIsLTcwMjg4Mzg4OSwtMjg2MDg2Njc0
LC0xNTU5NzA5MTQ4LDc2MjQ0ODI5MCwxNzc1MjA4NzEyXX0=
-->